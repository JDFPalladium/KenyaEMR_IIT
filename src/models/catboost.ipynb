{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbdac4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas numpy xgboost scikit-learn pyreadr matplotlib boto3 tqdm catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0ac3e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyreadr\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_recall_curve, auc, roc_curve\n",
    "from sklearn.utils import shuffle\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import os\n",
    "import boto3\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa81a0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define S3 info\n",
    "bucket_name = 'kehmisjan2025'\n",
    "file_key = 'targets_apr23.rds'\n",
    "\n",
    "# Initialize boto3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Download to a temporary file\n",
    "with tempfile.NamedTemporaryFile(suffix=\".rds\") as tmp_file:\n",
    "    s3.download_fileobj(bucket_name, file_key, tmp_file)\n",
    "    tmp_file.seek(0)  # go back to beginning\n",
    "    result = pyreadr.read_r(tmp_file.name)  # returns a dictionary\n",
    "\n",
    "# Extract the data frame\n",
    "iit_data = next(iter(result.values()))  # assumes only one object inside\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffce9527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(iit_data.dtypes) \n",
    "# Ensure the 'NAD' column is converted to datetime\n",
    "iit_data['NAD'] = pd.to_datetime(iit_data['NAD'], format='%Y-%m-%d')\n",
    "# iit_data['VisitDate'] = pd.to_datetime(iit_data['VisitDate'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe162624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the last quarter of the year\n",
    "# Define the date range to exclude\n",
    "start_exclude = pd.Timestamp('2024-10-01')\n",
    "end_exclude = pd.Timestamp('2024-12-31')\n",
    "\n",
    "# Filter out records from Sept through Dec 2024\n",
    "iit_data = iit_data[~((iit_data['NAD'] >= start_exclude) & (iit_data['NAD'] <= end_exclude))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cabea56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex\n",
      "Female    0.681077\n",
      "Male      0.318923\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(iit_data[\"Sex\"].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "662b34b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5914/735552305.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iit_data['is_friday'] = iit_data['Day'].apply(lambda x: 1 if x == \"Fri\" else 0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# iit_data['is_december'] = iit_data['Month'].apply(lambda x: 1 if x == \"December\" else 0)\n",
    "iit_data['is_friday'] = iit_data['Day'].apply(lambda x: 1 if x == \"Fri\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1403de56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-04 2024-09-28\n",
      "2022-01-01 00:00:00 2024-09-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(iit_data['VisitDate'].min(),iit_data['VisitDate'].max())\n",
    "print(iit_data['NAD'].min(),iit_data['NAD'].max())\n",
    "\n",
    "iit_data = iit_data.drop(columns=[\n",
    "    'OptimizedHIVRegimen', 'Drug', 'VisitDate', 'WHO_Missing', 'Type',\n",
    "    'most_recent_cd4', 'regimen_switch', 'AHD', 'NAD_Imputation_Flag',\n",
    "    'BMI_Missing', 'TimeatFacility', 'Adherence_Missing', 'Facility_type_category',\n",
    "    'Pregnant_Missing', 'Breastfeeding_Missing', 'Month', 'Day'\n",
    "    # 'lastvd' to 'months_since_restart' would go here\n",
    "    # 'Month', 'Day' handled below\n",
    "    \n",
    "])\n",
    "# iit_data = iit_data.drop(columns=iit_data.loc[:, 'men_knowledge':'women_sti'].columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "310ab571",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns= ['num_late_last3', 'num_late14_last3', 'num_late30_last3',\n",
    "       'num_late_last5', 'num_late14_last5', 'num_late30_last5',\n",
    "       'num_late_last10', 'num_late14_last10', 'num_late30_last10']\n",
    "iit_data[selected_columns] = iit_data[selected_columns].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7c44d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pregnant: Yes -> 1, No -> 0, else NA\n",
    "iit_data['Pregnant'] = iit_data['Pregnant'].map({'Yes': 1, 'No': 0}).astype('Int64')\n",
    "\n",
    "# Breastfeeding: Yes -> 1, No -> 0, else NA\n",
    "iit_data['Breastfeeding'] = iit_data['Breastfeeding'].map({'Yes': 1, 'No': 0}).astype('Int64')\n",
    "\n",
    "# ARTAdherence: good -> 1, poor/fair -> 0, else NA\n",
    "iit_data['ARTAdherence'] = iit_data['ARTAdherence'].map({\n",
    "    'good': 1,\n",
    "    'poor': 0,\n",
    "    'fair': 0\n",
    "}).astype('Int64')\n",
    "\n",
    "# Sex: Male -> 1, else 0\n",
    "iit_data['Sex'] = (iit_data['Sex'] == 'Male').astype('Int64')\n",
    "\n",
    "# Emr: KenyaEMR -> 1, else 0\n",
    "iit_data['Emr'] = (iit_data['Emr'] == 'KenyaEMR').astype('Int64')  # assuming there is an 'Emr' column\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e94ca15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_xgboost(dataset):\n",
    "    # List of categorical variables to be encoded\n",
    "    categorical_columns = [ 'BMI', 'WHOStage','most_recent_vl', 'MaritalStatus', 'EducationLevel','DifferentiatedCare',\n",
    "       'Occupation', 'VisitBy','TCAReason', 'cascade_status', 'Kephlevel','Ownertype'] \n",
    "    \n",
    "    # One-hot encoding the categorical columns\n",
    "    ohe = pd.get_dummies(dataset[categorical_columns], drop_first=True, dtype=int)\n",
    "    \n",
    "    # Concatenate the original dataset (excluding categorical columns) with the one-hot encoded columns\n",
    "    dataset_encoded = pd.concat([dataset.drop(columns=categorical_columns), ohe], axis=1)\n",
    "    \n",
    "    return dataset_encoded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4433037",
   "metadata": {},
   "source": [
    "Create folds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2a763a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "# Identify categorical features if known\n",
    "categorical_features = ['Kephlevel','DifferentiatedCare','WHOStage','most_recent_vl','MaritalStatus','EducationLevel',\n",
    " 'Occupation','VisitBy','BMI','TCAReason','cascade_status','Ownertype']  # Replace with actual names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "48166ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fold 1\n",
    "# ========== Train Data (Jan–May 2023) ==========\n",
    "train_data1 = iit_data.copy()\n",
    "train_data1 = train_data1.drop(columns=[\"SiteCode\"])\n",
    "train_data1 = train_data1[(train_data1[\"NAD\"] >= \"2023-01-01\") & (train_data1[\"NAD\"] <= \"2023-05-31\")]\n",
    "train_data1 = encode_xgboost(train_data1)\n",
    "train_labels1 = train_data1[\"iit\"]\n",
    "train_features1 = train_data1.drop(columns=[\"key\", \"NAD\", \"iit\"])\n",
    "\n",
    "train_pool1 = Pool(data=train_features1, label=train_labels1)\n",
    "\n",
    "# ========== Validation Data (June 2023) ==========\n",
    "val_data1 = iit_data.copy()\n",
    "val_data1 = val_data1.drop(columns=[\"SiteCode\"])\n",
    "val_data1 = val_data1[(val_data1[\"NAD\"] >= \"2023-06-01\") & (val_data1[\"NAD\"] <= \"2023-06-30\")]\n",
    "val_data1 = encode_xgboost(val_data1)\n",
    "val_labels1 = val_data1[\"iit\"]\n",
    "val_features1 = val_data1.drop(columns=[\"key\", \"NAD\", \"iit\"])\n",
    "\n",
    "val_pool1 = Pool(data=val_features1, label=val_labels1)\n",
    "\n",
    "# ========== Test Near Data (July 2023) ==========\n",
    "testnear_data1 = iit_data.copy()\n",
    "testnear_data1 = testnear_data1.drop(columns=[\"SiteCode\"])\n",
    "testnear_data1 = testnear_data1[(testnear_data1[\"NAD\"] >= \"2023-07-01\") & (testnear_data1[\"NAD\"] <= \"2023-07-31\")]\n",
    "testnear_data1 = encode_xgboost(testnear_data1)\n",
    "testnear_labels1 = testnear_data1[\"iit\"]\n",
    "testnear_features1 = testnear_data1.drop(columns=[\"key\", \"NAD\", \"iit\"])\n",
    "\n",
    "testnear_pool1 = Pool(data=testnear_features1, label=testnear_labels1)\n",
    "\n",
    "# ========== Test Data (July–Sept 2023) ==========\n",
    "test_data1 = iit_data.copy()\n",
    "test_data1 = test_data1.drop(columns=[\"SiteCode\"])\n",
    "test_data1 = test_data1[(test_data1[\"NAD\"] >= \"2023-07-01\") & (test_data1[\"NAD\"] <= \"2023-09-30\")]\n",
    "test_data1 = encode_xgboost(test_data1)\n",
    "test_labels1 = test_data1[\"iit\"]\n",
    "test_features1 = test_data1.drop(columns=[\"key\", \"NAD\", \"iit\"])\n",
    "\n",
    "test_pool1 = Pool(data=test_features1, label=test_labels1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6e7acbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fold 2\n",
    "# Train Data (Jan–May 2023)\n",
    "train_data2 = iit_data.copy()\n",
    "train_data2 = train_data2.drop(columns=[\"SiteCode\"])\n",
    "train_data2 = train_data2[(train_data2[\"NAD\"] >= \"2023-04-01\") & (train_data2[\"NAD\"] <= \"2023-08-30\")]\n",
    "train_data2 = encode_xgboost(train_data2)\n",
    "train_labels2 = train_data2[\"iit\"]\n",
    "train_features2 = train_data2.drop(columns=[\"key\", \"NAD\", \"iit\"])\n",
    "\n",
    "train_pool2 = Pool(data=train_features2, label=train_labels2)\n",
    "\n",
    "# Validation Data (June 2023)\n",
    "val_data2 = iit_data.copy()\n",
    "val_data2 = val_data2.drop(columns=[\"SiteCode\"])\n",
    "val_data2 = val_data2[(val_data2[\"NAD\"] >= \"2023-09-01\") & (val_data2[\"NAD\"] <= \"2023-09-30\")]\n",
    "val_data2 = encode_xgboost(val_data2)\n",
    "val_labels2 = val_data2[\"iit\"]\n",
    "val_features2 = val_data2.drop(columns=[\"key\", \"NAD\", \"iit\"])\n",
    "\n",
    "val_pool2 = Pool(data=val_features2, label=val_labels2)\n",
    "\n",
    "# Test Near Data (July 2023)\n",
    "testnear_data2 = iit_data.copy()\n",
    "testnear_data2 = testnear_data2.drop(columns=[\"SiteCode\"])\n",
    "testnear_data2 = testnear_data2[(testnear_data2[\"NAD\"] >= \"2023-10-01\") & (testnear_data2[\"NAD\"] <= \"2023-10-31\")]\n",
    "testnear_data2 = encode_xgboost(testnear_data2)\n",
    "testnear_labels2 = testnear_data2[\"iit\"]\n",
    "testnear_features2 = testnear_data2.drop(columns=[\"key\", \"NAD\", \"iit\"])\n",
    "\n",
    "testnear_pool2 = Pool(data=testnear_features2, label=testnear_labels2)\n",
    "# Test Data (July–Sept 2023)\n",
    "test_data2 = iit_data.copy()\n",
    "test_data2 = test_data2.drop(columns=[\"SiteCode\"])\n",
    "test_data2 = test_data2[(test_data2[\"NAD\"] >= \"2023-10-01\") & (test_data2[\"NAD\"] <= \"2023-12-31\")]\n",
    "test_data2 = encode_xgboost(test_data2)\n",
    "test_labels2 = test_data2[\"iit\"]\n",
    "test_features2 = test_data2.drop(columns=[\"key\", \"NAD\", \"iit\"])\n",
    "\n",
    "test_pool2 = Pool(data=test_features2, label=test_labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8e317bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fold 3\n",
    "\n",
    "train_data3 = iit_data.copy()\n",
    "train_data3 = train_data3.drop(columns=[\"SiteCode\"])\n",
    "train_data3 = train_data3[(train_data3[\"NAD\"] >= \"2023-06-01\") & (train_data3[\"NAD\"] <= \"2023-11-30\")]\n",
    "train_data3 = encode_xgboost(train_data3)\n",
    "train_labels3 = train_data3[\"iit\"]\n",
    "train_features3 = train_data3.drop(columns=[\"key\", \"NAD\", \"iit\"])\n",
    "\n",
    "train_pool3 = Pool(data=train_features3, label=train_labels3)\n",
    "\n",
    "# Validation Data (June 3033)\n",
    "val_data3 = iit_data.copy()\n",
    "val_data3 = val_data3.drop(columns=[\"SiteCode\"])\n",
    "val_data3 = val_data3[(val_data3[\"NAD\"] >= \"2023-12-01\") & (val_data3[\"NAD\"] <= \"2023-12-31\")]\n",
    "val_data3 = encode_xgboost(val_data3)\n",
    "val_labels3 = val_data3[\"iit\"]\n",
    "val_features3 = val_data3.drop(columns=[\"key\", \"NAD\", \"iit\"])\n",
    "\n",
    "val_pool3 = Pool(data=val_features3, label=val_labels3)\n",
    "\n",
    "# Test Near Data (July 3033)\n",
    "testnear_data3 = iit_data.copy()\n",
    "testnear_data3 = testnear_data3.drop(columns=[\"SiteCode\"])\n",
    "testnear_data3 = testnear_data3[(testnear_data3[\"NAD\"] >= \"2024-01-01\") & (testnear_data3[\"NAD\"] <= \"2024-01-31\")]\n",
    "testnear_data3 = encode_xgboost(testnear_data3)\n",
    "testnear_labels3 = testnear_data3[\"iit\"]\n",
    "testnear_features3 = testnear_data3.drop(columns=[\"key\", \"NAD\", \"iit\"])\n",
    "\n",
    "testnear_pool3 = Pool(data=testnear_features3, label=testnear_labels3)\n",
    "# Test Data (July–Sept 3033)\n",
    "test_data3 = iit_data.copy()\n",
    "test_data3 = test_data3.drop(columns=[\"SiteCode\"])\n",
    "test_data3 = test_data3[(test_data3[\"NAD\"] >= \"2024-01-01\") & (test_data3[\"NAD\"] <= \"2024-03-31\")]\n",
    "test_data3 = encode_xgboost(test_data3)\n",
    "test_labels3 = test_data3[\"iit\"]\n",
    "test_features3 = test_data3.drop(columns=[\"key\", \"NAD\", \"iit\"])\n",
    "\n",
    "test_pool3 = Pool(data=test_features3, label=test_labels3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a1a9f1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fold 4\n",
    "train_data4 = iit_data.copy()\n",
    "train_data4 = train_data4.drop(columns=[\"SiteCode\"])\n",
    "train_data4 = train_data4[(train_data4[\"NAD\"] >= \"2023-09-01\") & (train_data4[\"NAD\"] <= \"2024-02-29\")]\n",
    "train_data4= encode_xgboost(train_data4)\n",
    "train_labels4 = train_data4[\"iit\"]\n",
    "train_features4 = train_data4.drop(columns=[\"key\", \"NAD\", \"iit\"])\n",
    "\n",
    "train_pool4 = Pool(data=train_features4, label=train_labels4)\n",
    "\n",
    "# Validation Data (June 4044)\n",
    "val_data4 = iit_data.copy()\n",
    "val_data4 = val_data4.drop(columns=[\"SiteCode\"])\n",
    "val_data4 = val_data4[(val_data4[\"NAD\"] >= \"2024-03-01\") & (val_data4[\"NAD\"] <= \"2024-03-31\")]\n",
    "val_data4= encode_xgboost(val_data4)\n",
    "val_labels4 = val_data4[\"iit\"]\n",
    "val_features4 = val_data4.drop(columns=[\"key\", \"NAD\", \"iit\"])\n",
    "\n",
    "val_pool4 = Pool(data=val_features4, label=val_labels4)\n",
    "\n",
    "\n",
    "# Test Near Data (July 4044)\n",
    "testnear_data4 = iit_data.copy()\n",
    "testnear_data4 = testnear_data4.drop(columns=[\"SiteCode\"])\n",
    "testnear_data4 = testnear_data4[(testnear_data4[\"NAD\"] >= \"2024-04-01\") & (testnear_data4[\"NAD\"] <= \"2024-04-30\")]\n",
    "testnear_data4= encode_xgboost(testnear_data4)\n",
    "testnear_labels4 = testnear_data4[\"iit\"]\n",
    "testnear_features4 = testnear_data4.drop(columns=[\"key\", \"NAD\", \"iit\"])\n",
    "\n",
    "testnear_pool4 = Pool(data=testnear_features4, label=testnear_labels4)\n",
    "\n",
    "# Test Data (July–Sept 4044)\n",
    "test_data4 = iit_data.copy()\n",
    "test_data4 = test_data4.drop(columns=[\"SiteCode\"])\n",
    "test_data4 = test_data4[(test_data4[\"NAD\"] >= \"2024-04-01\") & (test_data4[\"NAD\"] <= \"2024-06-30\")]\n",
    "test_data4=encode_xgboost(test_data4)\n",
    "test_labels4 = test_data4[\"iit\"]\n",
    "test_features4 = test_data4.drop(columns=[\"key\", \"NAD\", \"iit\"])\n",
    "\n",
    "test_pool4 = Pool(data=test_features4, label=test_labels4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "687ba1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fold 5\n",
    "\n",
    "train_data5 = iit_data.copy()\n",
    "train_data5 = train_data5.drop(columns=[\"SiteCode\"])\n",
    "train_data5 = train_data5[(train_data5[\"NAD\"] >= \"2024-01-01\") & (train_data5[\"NAD\"] <= \"2024-05-31\")]\n",
    "train_data5= encode_xgboost(train_data5)\n",
    "train_labels5 = train_data5[\"iit\"]\n",
    "train_features5 = train_data5.drop(columns=[\"key\", \"NAD\", \"iit\"])\n",
    "\n",
    "train_pool5 = Pool(data=train_features5, label=train_labels5)\n",
    "\n",
    "\n",
    "# Validation Data (June 5055)\n",
    "val_data5 = iit_data.copy()\n",
    "val_data5 = val_data5.drop(columns=[\"SiteCode\"])\n",
    "val_data5 = val_data5[(val_data5[\"NAD\"] >= \"2024-06-01\") & (val_data5[\"NAD\"] <= \"2024-06-30\")]\n",
    "val_data5= encode_xgboost(val_data5)\n",
    "val_labels5 = val_data5[\"iit\"]\n",
    "val_features5 = val_data5.drop(columns=[\"key\", \"NAD\", \"iit\"])\n",
    "\n",
    "val_pool5 = Pool(data=val_features5, label=val_labels5)\n",
    "\n",
    "# Test Near Data (July 5055)\n",
    "testnear_data5 = iit_data.copy()\n",
    "testnear_data5 = testnear_data5.drop(columns=[\"SiteCode\"])\n",
    "testnear_data5 = testnear_data5[(testnear_data5[\"NAD\"] >= \"2024-07-01\") & (testnear_data5[\"NAD\"] <= \"2024-07-30\")]\n",
    "testnear_data5= encode_xgboost(testnear_data5)\n",
    "testnear_labels5 = testnear_data5[\"iit\"]\n",
    "testnear_features5 = testnear_data5.drop(columns=[\"key\", \"NAD\", \"iit\"])\n",
    "\n",
    "testnear_pool5 = Pool(data=testnear_features5, label=testnear_labels5)\n",
    "# Test Data (July–Sept 5055)\n",
    "test_data5 = iit_data.copy()\n",
    "test_data5 = test_data5.drop(columns=[\"SiteCode\"])\n",
    "test_data5 = test_data5[(test_data5[\"NAD\"] >= \"2024-07-01\") & (test_data5[\"NAD\"] <= \"2024-09-30\")]\n",
    "test_data5= encode_xgboost(test_data5)\n",
    "test_labels5 = test_data5[\"iit\"]\n",
    "test_features5 = test_data5.drop(columns=[\"key\", \"NAD\", \"iit\"])\n",
    "\n",
    "test_pool5 = Pool(data=test_features5, label=test_labels5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7f06f865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your existing fold structure using CatBoost Pools and raw test DataFrames\n",
    "fold_list = {\n",
    "    \"fold1\": [train_pool1, val_pool1, testnear_pool1, test_pool1, testnear_data1, test_data1],\n",
    "    \"fold2\": [train_pool2, val_pool2, testnear_pool2, test_pool2, testnear_data2, test_data2],\n",
    "    \"fold3\": [train_pool3, val_pool3, testnear_pool3, test_pool3, testnear_data3, test_data3],\n",
    "    \"fold4\": [train_pool4, val_pool4, testnear_pool4, test_pool4, testnear_data4, test_data4],\n",
    "    \"fold5\": [train_pool5, val_pool5, testnear_pool5, test_pool5, testnear_data5, test_data5]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c22ce44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from itertools import product\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "# Step 1: Create the grid\n",
    "params_grid = list(product(\n",
    "    [0.05, 0.1],                  # eta\n",
    "    [6, 8],               # max_depth\n",
    "    [0.5, 0.8],           # subsample\n",
    "    [0.6],           # colsample_bytree\n",
    "    [1, 10],                     # lambda\n",
    "    [50]                  # scale_pos_weight\n",
    "))\n",
    "\n",
    "# Build DataFrame\n",
    "grid_sparse = pd.DataFrame(params_grid, columns=[\n",
    "    \"eta\", \"max_depth\", \"subsample\", \"col_sample\", \"lambda_\", \"scale_pos_weight\"\n",
    "])\n",
    "# Add empty columns for PR AUCs\n",
    "for k in range(1, 6):\n",
    "    grid_sparse[f\"val_pr_auc_near_{k}\"] = np.nan\n",
    "    grid_sparse[f\"val_pr_auc_{k}\"] = np.nan\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd23bfc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eta</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>subsample</th>\n",
       "      <th>col_sample</th>\n",
       "      <th>lambda_</th>\n",
       "      <th>scale_pos_weight</th>\n",
       "      <th>val_pr_auc_near_1</th>\n",
       "      <th>val_pr_auc_1</th>\n",
       "      <th>val_pr_auc_near_2</th>\n",
       "      <th>val_pr_auc_2</th>\n",
       "      <th>val_pr_auc_near_3</th>\n",
       "      <th>val_pr_auc_3</th>\n",
       "      <th>val_pr_auc_near_4</th>\n",
       "      <th>val_pr_auc_4</th>\n",
       "      <th>val_pr_auc_near_5</th>\n",
       "      <th>val_pr_auc_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.05</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.05</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.05</td>\n",
       "      <td>8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.05</td>\n",
       "      <td>8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.05</td>\n",
       "      <td>8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.05</td>\n",
       "      <td>8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     eta  max_depth  subsample  col_sample  lambda_  scale_pos_weight  \\\n",
       "0   0.05          6        0.5         0.6        1                50   \n",
       "1   0.05          6        0.5         0.6       10                50   \n",
       "2   0.05          6        0.8         0.6        1                50   \n",
       "3   0.05          6        0.8         0.6       10                50   \n",
       "4   0.05          8        0.5         0.6        1                50   \n",
       "5   0.05          8        0.5         0.6       10                50   \n",
       "6   0.05          8        0.8         0.6        1                50   \n",
       "7   0.05          8        0.8         0.6       10                50   \n",
       "8   0.10          6        0.5         0.6        1                50   \n",
       "9   0.10          6        0.5         0.6       10                50   \n",
       "10  0.10          6        0.8         0.6        1                50   \n",
       "11  0.10          6        0.8         0.6       10                50   \n",
       "12  0.10          8        0.5         0.6        1                50   \n",
       "13  0.10          8        0.5         0.6       10                50   \n",
       "14  0.10          8        0.8         0.6        1                50   \n",
       "15  0.10          8        0.8         0.6       10                50   \n",
       "\n",
       "    val_pr_auc_near_1  val_pr_auc_1  val_pr_auc_near_2  val_pr_auc_2  \\\n",
       "0                 NaN           NaN                NaN           NaN   \n",
       "1                 NaN           NaN                NaN           NaN   \n",
       "2                 NaN           NaN                NaN           NaN   \n",
       "3                 NaN           NaN                NaN           NaN   \n",
       "4                 NaN           NaN                NaN           NaN   \n",
       "5                 NaN           NaN                NaN           NaN   \n",
       "6                 NaN           NaN                NaN           NaN   \n",
       "7                 NaN           NaN                NaN           NaN   \n",
       "8                 NaN           NaN                NaN           NaN   \n",
       "9                 NaN           NaN                NaN           NaN   \n",
       "10                NaN           NaN                NaN           NaN   \n",
       "11                NaN           NaN                NaN           NaN   \n",
       "12                NaN           NaN                NaN           NaN   \n",
       "13                NaN           NaN                NaN           NaN   \n",
       "14                NaN           NaN                NaN           NaN   \n",
       "15                NaN           NaN                NaN           NaN   \n",
       "\n",
       "    val_pr_auc_near_3  val_pr_auc_3  val_pr_auc_near_4  val_pr_auc_4  \\\n",
       "0                 NaN           NaN                NaN           NaN   \n",
       "1                 NaN           NaN                NaN           NaN   \n",
       "2                 NaN           NaN                NaN           NaN   \n",
       "3                 NaN           NaN                NaN           NaN   \n",
       "4                 NaN           NaN                NaN           NaN   \n",
       "5                 NaN           NaN                NaN           NaN   \n",
       "6                 NaN           NaN                NaN           NaN   \n",
       "7                 NaN           NaN                NaN           NaN   \n",
       "8                 NaN           NaN                NaN           NaN   \n",
       "9                 NaN           NaN                NaN           NaN   \n",
       "10                NaN           NaN                NaN           NaN   \n",
       "11                NaN           NaN                NaN           NaN   \n",
       "12                NaN           NaN                NaN           NaN   \n",
       "13                NaN           NaN                NaN           NaN   \n",
       "14                NaN           NaN                NaN           NaN   \n",
       "15                NaN           NaN                NaN           NaN   \n",
       "\n",
       "    val_pr_auc_near_5  val_pr_auc_5  \n",
       "0                 NaN           NaN  \n",
       "1                 NaN           NaN  \n",
       "2                 NaN           NaN  \n",
       "3                 NaN           NaN  \n",
       "4                 NaN           NaN  \n",
       "5                 NaN           NaN  \n",
       "6                 NaN           NaN  \n",
       "7                 NaN           NaN  \n",
       "8                 NaN           NaN  \n",
       "9                 NaN           NaN  \n",
       "10                NaN           NaN  \n",
       "11                NaN           NaN  \n",
       "12                NaN           NaN  \n",
       "13                NaN           NaN  \n",
       "14                NaN           NaN  \n",
       "15                NaN           NaN  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9236b53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:   6%|▋         | 1/16 [13:17<3:19:19, 797.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta                   0.050000\n",
      "max_depth             6.000000\n",
      "subsample             0.500000\n",
      "col_sample            0.600000\n",
      "lambda_               1.000000\n",
      "scale_pos_weight     50.000000\n",
      "val_pr_auc_near_1     0.160344\n",
      "val_pr_auc_1          0.164269\n",
      "val_pr_auc_near_2     0.194221\n",
      "val_pr_auc_2          0.170676\n",
      "val_pr_auc_near_3     0.143216\n",
      "val_pr_auc_3          0.123820\n",
      "val_pr_auc_near_4     0.131218\n",
      "val_pr_auc_4          0.125694\n",
      "val_pr_auc_near_5     0.140735\n",
      "val_pr_auc_5          0.131620\n",
      "Name: 0, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:  12%|█▎        | 2/16 [27:10<3:11:01, 818.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta                   0.050000\n",
      "max_depth             6.000000\n",
      "subsample             0.500000\n",
      "col_sample            0.600000\n",
      "lambda_              10.000000\n",
      "scale_pos_weight     50.000000\n",
      "val_pr_auc_near_1     0.160884\n",
      "val_pr_auc_1          0.163165\n",
      "val_pr_auc_near_2     0.190773\n",
      "val_pr_auc_2          0.168372\n",
      "val_pr_auc_near_3     0.142813\n",
      "val_pr_auc_3          0.123439\n",
      "val_pr_auc_near_4     0.130563\n",
      "val_pr_auc_4          0.125050\n",
      "val_pr_auc_near_5     0.142261\n",
      "val_pr_auc_5          0.131808\n",
      "Name: 1, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:  19%|█▉        | 3/16 [42:35<3:07:53, 867.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta                   0.050000\n",
      "max_depth             6.000000\n",
      "subsample             0.800000\n",
      "col_sample            0.600000\n",
      "lambda_               1.000000\n",
      "scale_pos_weight     50.000000\n",
      "val_pr_auc_near_1     0.158790\n",
      "val_pr_auc_1          0.163828\n",
      "val_pr_auc_near_2     0.190346\n",
      "val_pr_auc_2          0.168443\n",
      "val_pr_auc_near_3     0.142176\n",
      "val_pr_auc_3          0.123082\n",
      "val_pr_auc_near_4     0.130075\n",
      "val_pr_auc_4          0.124137\n",
      "val_pr_auc_near_5     0.142039\n",
      "val_pr_auc_5          0.132118\n",
      "Name: 2, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:  25%|██▌       | 4/16 [58:23<2:59:46, 898.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta                   0.050000\n",
      "max_depth             6.000000\n",
      "subsample             0.800000\n",
      "col_sample            0.600000\n",
      "lambda_              10.000000\n",
      "scale_pos_weight     50.000000\n",
      "val_pr_auc_near_1     0.157938\n",
      "val_pr_auc_1          0.162837\n",
      "val_pr_auc_near_2     0.190084\n",
      "val_pr_auc_2          0.167982\n",
      "val_pr_auc_near_3     0.141925\n",
      "val_pr_auc_3          0.123119\n",
      "val_pr_auc_near_4     0.130242\n",
      "val_pr_auc_4          0.125001\n",
      "val_pr_auc_near_5     0.140601\n",
      "val_pr_auc_5          0.131839\n",
      "Name: 3, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:  31%|███▏      | 5/16 [1:06:52<2:19:02, 758.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta                   0.050000\n",
      "max_depth             8.000000\n",
      "subsample             0.500000\n",
      "col_sample            0.600000\n",
      "lambda_               1.000000\n",
      "scale_pos_weight     50.000000\n",
      "val_pr_auc_near_1     0.160075\n",
      "val_pr_auc_1          0.162118\n",
      "val_pr_auc_near_2     0.191238\n",
      "val_pr_auc_2          0.169153\n",
      "val_pr_auc_near_3     0.141187\n",
      "val_pr_auc_3          0.123432\n",
      "val_pr_auc_near_4     0.133065\n",
      "val_pr_auc_4          0.126577\n",
      "val_pr_auc_near_5     0.140374\n",
      "val_pr_auc_5          0.130755\n",
      "Name: 4, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:  38%|███▊      | 6/16 [1:17:13<1:58:35, 711.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta                   0.050000\n",
      "max_depth             8.000000\n",
      "subsample             0.500000\n",
      "col_sample            0.600000\n",
      "lambda_              10.000000\n",
      "scale_pos_weight     50.000000\n",
      "val_pr_auc_near_1     0.163266\n",
      "val_pr_auc_1          0.164597\n",
      "val_pr_auc_near_2     0.193341\n",
      "val_pr_auc_2          0.170131\n",
      "val_pr_auc_near_3     0.143173\n",
      "val_pr_auc_3          0.124383\n",
      "val_pr_auc_near_4     0.133261\n",
      "val_pr_auc_4          0.127327\n",
      "val_pr_auc_near_5     0.141259\n",
      "val_pr_auc_5          0.131103\n",
      "Name: 5, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:  44%|████▍     | 7/16 [1:26:33<1:39:18, 662.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta                   0.050000\n",
      "max_depth             8.000000\n",
      "subsample             0.800000\n",
      "col_sample            0.600000\n",
      "lambda_               1.000000\n",
      "scale_pos_weight     50.000000\n",
      "val_pr_auc_near_1     0.160277\n",
      "val_pr_auc_1          0.162724\n",
      "val_pr_auc_near_2     0.189925\n",
      "val_pr_auc_2          0.167643\n",
      "val_pr_auc_near_3     0.142757\n",
      "val_pr_auc_3          0.124305\n",
      "val_pr_auc_near_4     0.132593\n",
      "val_pr_auc_4          0.126327\n",
      "val_pr_auc_near_5     0.141685\n",
      "val_pr_auc_5          0.131386\n",
      "Name: 6, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:  50%|█████     | 8/16 [1:39:55<1:34:13, 706.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta                   0.050000\n",
      "max_depth             8.000000\n",
      "subsample             0.800000\n",
      "col_sample            0.600000\n",
      "lambda_              10.000000\n",
      "scale_pos_weight     50.000000\n",
      "val_pr_auc_near_1     0.161401\n",
      "val_pr_auc_1          0.164569\n",
      "val_pr_auc_near_2     0.191953\n",
      "val_pr_auc_2          0.169154\n",
      "val_pr_auc_near_3     0.144538\n",
      "val_pr_auc_3          0.124941\n",
      "val_pr_auc_near_4     0.133889\n",
      "val_pr_auc_4          0.127963\n",
      "val_pr_auc_near_5     0.143071\n",
      "val_pr_auc_5          0.132283\n",
      "Name: 7, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:  56%|█████▋    | 9/16 [1:46:43<1:11:33, 613.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta                   0.100000\n",
      "max_depth             6.000000\n",
      "subsample             0.500000\n",
      "col_sample            0.600000\n",
      "lambda_               1.000000\n",
      "scale_pos_weight     50.000000\n",
      "val_pr_auc_near_1     0.158036\n",
      "val_pr_auc_1          0.162947\n",
      "val_pr_auc_near_2     0.189509\n",
      "val_pr_auc_2          0.166009\n",
      "val_pr_auc_near_3     0.140842\n",
      "val_pr_auc_3          0.122617\n",
      "val_pr_auc_near_4     0.128429\n",
      "val_pr_auc_4          0.123759\n",
      "val_pr_auc_near_5     0.141372\n",
      "val_pr_auc_5          0.131742\n",
      "Name: 8, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:  62%|██████▎   | 10/16 [1:54:59<57:42, 577.16s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta                   0.100000\n",
      "max_depth             6.000000\n",
      "subsample             0.500000\n",
      "col_sample            0.600000\n",
      "lambda_              10.000000\n",
      "scale_pos_weight     50.000000\n",
      "val_pr_auc_near_1     0.159461\n",
      "val_pr_auc_1          0.163085\n",
      "val_pr_auc_near_2     0.191616\n",
      "val_pr_auc_2          0.168769\n",
      "val_pr_auc_near_3     0.140779\n",
      "val_pr_auc_3          0.121947\n",
      "val_pr_auc_near_4     0.129759\n",
      "val_pr_auc_4          0.125277\n",
      "val_pr_auc_near_5     0.140836\n",
      "val_pr_auc_5          0.131464\n",
      "Name: 9, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:  69%|██████▉   | 11/16 [2:03:02<45:41, 548.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta                   0.100000\n",
      "max_depth             6.000000\n",
      "subsample             0.800000\n",
      "col_sample            0.600000\n",
      "lambda_               1.000000\n",
      "scale_pos_weight     50.000000\n",
      "val_pr_auc_near_1     0.157535\n",
      "val_pr_auc_1          0.162137\n",
      "val_pr_auc_near_2     0.193300\n",
      "val_pr_auc_2          0.169517\n",
      "val_pr_auc_near_3     0.140610\n",
      "val_pr_auc_3          0.122157\n",
      "val_pr_auc_near_4     0.129993\n",
      "val_pr_auc_4          0.124670\n",
      "val_pr_auc_near_5     0.142234\n",
      "val_pr_auc_5          0.132046\n",
      "Name: 10, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:  75%|███████▌  | 12/16 [2:11:28<35:42, 535.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta                   0.100000\n",
      "max_depth             6.000000\n",
      "subsample             0.800000\n",
      "col_sample            0.600000\n",
      "lambda_              10.000000\n",
      "scale_pos_weight     50.000000\n",
      "val_pr_auc_near_1     0.158048\n",
      "val_pr_auc_1          0.161828\n",
      "val_pr_auc_near_2     0.191914\n",
      "val_pr_auc_2          0.168471\n",
      "val_pr_auc_near_3     0.141883\n",
      "val_pr_auc_3          0.122430\n",
      "val_pr_auc_near_4     0.127209\n",
      "val_pr_auc_4          0.123386\n",
      "val_pr_auc_near_5     0.142033\n",
      "val_pr_auc_5          0.132084\n",
      "Name: 11, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:  81%|████████▏ | 13/16 [2:16:37<23:20, 466.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta                   0.100000\n",
      "max_depth             8.000000\n",
      "subsample             0.500000\n",
      "col_sample            0.600000\n",
      "lambda_               1.000000\n",
      "scale_pos_weight     50.000000\n",
      "val_pr_auc_near_1     0.158522\n",
      "val_pr_auc_1          0.160548\n",
      "val_pr_auc_near_2     0.192108\n",
      "val_pr_auc_2          0.168947\n",
      "val_pr_auc_near_3     0.142138\n",
      "val_pr_auc_3          0.123486\n",
      "val_pr_auc_near_4     0.130762\n",
      "val_pr_auc_4          0.124594\n",
      "val_pr_auc_near_5     0.142259\n",
      "val_pr_auc_5          0.131669\n",
      "Name: 12, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:  88%|████████▊ | 14/16 [2:22:18<14:17, 428.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta                   0.100000\n",
      "max_depth             8.000000\n",
      "subsample             0.500000\n",
      "col_sample            0.600000\n",
      "lambda_              10.000000\n",
      "scale_pos_weight     50.000000\n",
      "val_pr_auc_near_1     0.161723\n",
      "val_pr_auc_1          0.162474\n",
      "val_pr_auc_near_2     0.191006\n",
      "val_pr_auc_2          0.168407\n",
      "val_pr_auc_near_3     0.142149\n",
      "val_pr_auc_3          0.122890\n",
      "val_pr_auc_near_4     0.131219\n",
      "val_pr_auc_4          0.125406\n",
      "val_pr_auc_near_5     0.142250\n",
      "val_pr_auc_5          0.132223\n",
      "Name: 13, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:  94%|█████████▍| 15/16 [2:27:57<06:41, 401.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta                   0.100000\n",
      "max_depth             8.000000\n",
      "subsample             0.800000\n",
      "col_sample            0.600000\n",
      "lambda_               1.000000\n",
      "scale_pos_weight     50.000000\n",
      "val_pr_auc_near_1     0.161750\n",
      "val_pr_auc_1          0.163322\n",
      "val_pr_auc_near_2     0.190948\n",
      "val_pr_auc_2          0.168404\n",
      "val_pr_auc_near_3     0.139990\n",
      "val_pr_auc_3          0.122780\n",
      "val_pr_auc_near_4     0.131664\n",
      "val_pr_auc_4          0.125794\n",
      "val_pr_auc_near_5     0.141398\n",
      "val_pr_auc_5          0.132029\n",
      "Name: 14, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search: 100%|██████████| 16/16 [2:34:58<00:00, 581.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta                   0.100000\n",
      "max_depth             8.000000\n",
      "subsample             0.800000\n",
      "col_sample            0.600000\n",
      "lambda_              10.000000\n",
      "scale_pos_weight     50.000000\n",
      "val_pr_auc_near_1     0.160438\n",
      "val_pr_auc_1          0.162332\n",
      "val_pr_auc_near_2     0.189557\n",
      "val_pr_auc_2          0.167908\n",
      "val_pr_auc_near_3     0.142023\n",
      "val_pr_auc_3          0.123051\n",
      "val_pr_auc_near_4     0.131156\n",
      "val_pr_auc_4          0.126033\n",
      "val_pr_auc_near_5     0.142284\n",
      "val_pr_auc_5          0.131420\n",
      "Name: 15, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.metrics import average_precision_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Grid search loop\n",
    "for i in tqdm(range(len(grid_sparse)), desc=\"Grid Search\"):\n",
    "\n",
    "    row = grid_sparse.iloc[i]\n",
    "\n",
    "    for k in tqdm(range(1, 6), desc=f\"Fold {i+1}\", leave=False):\n",
    "\n",
    "        dtrain, dval, dtestnear, dtest, test_near, test_data = fold_list[f\"fold{k}\"]\n",
    "\n",
    "        model = CatBoostClassifier(\n",
    "            iterations=3000,\n",
    "            learning_rate=row[\"eta\"],\n",
    "            depth=int(row[\"max_depth\"]),\n",
    "            subsample=row[\"subsample\"],\n",
    "            colsample_bylevel=row[\"col_sample\"],\n",
    "            l2_leaf_reg=row[\"lambda_\"],\n",
    "            scale_pos_weight=row[\"scale_pos_weight\"],\n",
    "            eval_metric=\"AUC\",\n",
    "            loss_function=\"Logloss\",\n",
    "            verbose=False,\n",
    "            early_stopping_rounds=100,\n",
    "            random_seed=42\n",
    "        )\n",
    "\n",
    "        # Fit model\n",
    "        model.fit(dtrain, eval_set=dval)\n",
    "\n",
    "        # Predict on testnear\n",
    "        testnear_preds = model.predict_proba(dtestnear)[:, 1]\n",
    "        ap_near = average_precision_score(test_near[\"iit\"], testnear_preds)\n",
    "        grid_sparse.at[grid_sparse.index[i], f\"val_pr_auc_near_{k}\"] = ap_near\n",
    "\n",
    "        # Predict on test\n",
    "        test_preds = model.predict_proba(dtest)[:, 1]\n",
    "        ap = average_precision_score(test_data[\"iit\"], test_preds)\n",
    "        grid_sparse.at[grid_sparse.index[i], f\"val_pr_auc_{k}\"] = ap\n",
    "\n",
    "    print(grid_sparse.iloc[i])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e366c742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eta</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>subsample</th>\n",
       "      <th>col_sample</th>\n",
       "      <th>lambda_</th>\n",
       "      <th>scale_pos_weight</th>\n",
       "      <th>val_pr_auc_near_1</th>\n",
       "      <th>val_pr_auc_1</th>\n",
       "      <th>val_pr_auc_near_2</th>\n",
       "      <th>val_pr_auc_2</th>\n",
       "      <th>val_pr_auc_near_3</th>\n",
       "      <th>val_pr_auc_3</th>\n",
       "      <th>val_pr_auc_near_4</th>\n",
       "      <th>val_pr_auc_4</th>\n",
       "      <th>val_pr_auc_near_5</th>\n",
       "      <th>val_pr_auc_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.160344</td>\n",
       "      <td>0.164269</td>\n",
       "      <td>0.194221</td>\n",
       "      <td>0.170676</td>\n",
       "      <td>0.143216</td>\n",
       "      <td>0.123820</td>\n",
       "      <td>0.131218</td>\n",
       "      <td>0.125694</td>\n",
       "      <td>0.140735</td>\n",
       "      <td>0.131620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.160884</td>\n",
       "      <td>0.163165</td>\n",
       "      <td>0.190773</td>\n",
       "      <td>0.168372</td>\n",
       "      <td>0.142813</td>\n",
       "      <td>0.123439</td>\n",
       "      <td>0.130563</td>\n",
       "      <td>0.125050</td>\n",
       "      <td>0.142261</td>\n",
       "      <td>0.131808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.05</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.158790</td>\n",
       "      <td>0.163828</td>\n",
       "      <td>0.190346</td>\n",
       "      <td>0.168443</td>\n",
       "      <td>0.142176</td>\n",
       "      <td>0.123082</td>\n",
       "      <td>0.130075</td>\n",
       "      <td>0.124137</td>\n",
       "      <td>0.142039</td>\n",
       "      <td>0.132118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.05</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.157938</td>\n",
       "      <td>0.162837</td>\n",
       "      <td>0.190084</td>\n",
       "      <td>0.167982</td>\n",
       "      <td>0.141925</td>\n",
       "      <td>0.123119</td>\n",
       "      <td>0.130242</td>\n",
       "      <td>0.125001</td>\n",
       "      <td>0.140601</td>\n",
       "      <td>0.131839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.05</td>\n",
       "      <td>8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.160075</td>\n",
       "      <td>0.162118</td>\n",
       "      <td>0.191238</td>\n",
       "      <td>0.169153</td>\n",
       "      <td>0.141187</td>\n",
       "      <td>0.123432</td>\n",
       "      <td>0.133065</td>\n",
       "      <td>0.126577</td>\n",
       "      <td>0.140374</td>\n",
       "      <td>0.130755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.05</td>\n",
       "      <td>8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.163266</td>\n",
       "      <td>0.164597</td>\n",
       "      <td>0.193341</td>\n",
       "      <td>0.170131</td>\n",
       "      <td>0.143173</td>\n",
       "      <td>0.124383</td>\n",
       "      <td>0.133261</td>\n",
       "      <td>0.127327</td>\n",
       "      <td>0.141259</td>\n",
       "      <td>0.131103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.05</td>\n",
       "      <td>8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.160277</td>\n",
       "      <td>0.162724</td>\n",
       "      <td>0.189925</td>\n",
       "      <td>0.167643</td>\n",
       "      <td>0.142757</td>\n",
       "      <td>0.124305</td>\n",
       "      <td>0.132593</td>\n",
       "      <td>0.126327</td>\n",
       "      <td>0.141685</td>\n",
       "      <td>0.131386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.05</td>\n",
       "      <td>8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.161401</td>\n",
       "      <td>0.164569</td>\n",
       "      <td>0.191953</td>\n",
       "      <td>0.169154</td>\n",
       "      <td>0.144538</td>\n",
       "      <td>0.124941</td>\n",
       "      <td>0.133889</td>\n",
       "      <td>0.127963</td>\n",
       "      <td>0.143071</td>\n",
       "      <td>0.132283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.158036</td>\n",
       "      <td>0.162947</td>\n",
       "      <td>0.189509</td>\n",
       "      <td>0.166009</td>\n",
       "      <td>0.140842</td>\n",
       "      <td>0.122617</td>\n",
       "      <td>0.128429</td>\n",
       "      <td>0.123759</td>\n",
       "      <td>0.141372</td>\n",
       "      <td>0.131742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.159461</td>\n",
       "      <td>0.163085</td>\n",
       "      <td>0.191616</td>\n",
       "      <td>0.168769</td>\n",
       "      <td>0.140779</td>\n",
       "      <td>0.121947</td>\n",
       "      <td>0.129759</td>\n",
       "      <td>0.125277</td>\n",
       "      <td>0.140836</td>\n",
       "      <td>0.131464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.157535</td>\n",
       "      <td>0.162137</td>\n",
       "      <td>0.193300</td>\n",
       "      <td>0.169517</td>\n",
       "      <td>0.140610</td>\n",
       "      <td>0.122157</td>\n",
       "      <td>0.129993</td>\n",
       "      <td>0.124670</td>\n",
       "      <td>0.142234</td>\n",
       "      <td>0.132046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.158048</td>\n",
       "      <td>0.161828</td>\n",
       "      <td>0.191914</td>\n",
       "      <td>0.168471</td>\n",
       "      <td>0.141883</td>\n",
       "      <td>0.122430</td>\n",
       "      <td>0.127209</td>\n",
       "      <td>0.123386</td>\n",
       "      <td>0.142033</td>\n",
       "      <td>0.132084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.158522</td>\n",
       "      <td>0.160548</td>\n",
       "      <td>0.192108</td>\n",
       "      <td>0.168947</td>\n",
       "      <td>0.142138</td>\n",
       "      <td>0.123486</td>\n",
       "      <td>0.130762</td>\n",
       "      <td>0.124594</td>\n",
       "      <td>0.142259</td>\n",
       "      <td>0.131669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.161723</td>\n",
       "      <td>0.162474</td>\n",
       "      <td>0.191006</td>\n",
       "      <td>0.168407</td>\n",
       "      <td>0.142149</td>\n",
       "      <td>0.122890</td>\n",
       "      <td>0.131219</td>\n",
       "      <td>0.125406</td>\n",
       "      <td>0.142250</td>\n",
       "      <td>0.132223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.161750</td>\n",
       "      <td>0.163322</td>\n",
       "      <td>0.190948</td>\n",
       "      <td>0.168404</td>\n",
       "      <td>0.139990</td>\n",
       "      <td>0.122780</td>\n",
       "      <td>0.131664</td>\n",
       "      <td>0.125794</td>\n",
       "      <td>0.141398</td>\n",
       "      <td>0.132029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.160438</td>\n",
       "      <td>0.162332</td>\n",
       "      <td>0.189557</td>\n",
       "      <td>0.167908</td>\n",
       "      <td>0.142023</td>\n",
       "      <td>0.123051</td>\n",
       "      <td>0.131156</td>\n",
       "      <td>0.126033</td>\n",
       "      <td>0.142284</td>\n",
       "      <td>0.131420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     eta  max_depth  subsample  col_sample  lambda_  scale_pos_weight  \\\n",
       "0   0.05          6        0.5         0.6        1                50   \n",
       "1   0.05          6        0.5         0.6       10                50   \n",
       "2   0.05          6        0.8         0.6        1                50   \n",
       "3   0.05          6        0.8         0.6       10                50   \n",
       "4   0.05          8        0.5         0.6        1                50   \n",
       "5   0.05          8        0.5         0.6       10                50   \n",
       "6   0.05          8        0.8         0.6        1                50   \n",
       "7   0.05          8        0.8         0.6       10                50   \n",
       "8   0.10          6        0.5         0.6        1                50   \n",
       "9   0.10          6        0.5         0.6       10                50   \n",
       "10  0.10          6        0.8         0.6        1                50   \n",
       "11  0.10          6        0.8         0.6       10                50   \n",
       "12  0.10          8        0.5         0.6        1                50   \n",
       "13  0.10          8        0.5         0.6       10                50   \n",
       "14  0.10          8        0.8         0.6        1                50   \n",
       "15  0.10          8        0.8         0.6       10                50   \n",
       "\n",
       "    val_pr_auc_near_1  val_pr_auc_1  val_pr_auc_near_2  val_pr_auc_2  \\\n",
       "0            0.160344      0.164269           0.194221      0.170676   \n",
       "1            0.160884      0.163165           0.190773      0.168372   \n",
       "2            0.158790      0.163828           0.190346      0.168443   \n",
       "3            0.157938      0.162837           0.190084      0.167982   \n",
       "4            0.160075      0.162118           0.191238      0.169153   \n",
       "5            0.163266      0.164597           0.193341      0.170131   \n",
       "6            0.160277      0.162724           0.189925      0.167643   \n",
       "7            0.161401      0.164569           0.191953      0.169154   \n",
       "8            0.158036      0.162947           0.189509      0.166009   \n",
       "9            0.159461      0.163085           0.191616      0.168769   \n",
       "10           0.157535      0.162137           0.193300      0.169517   \n",
       "11           0.158048      0.161828           0.191914      0.168471   \n",
       "12           0.158522      0.160548           0.192108      0.168947   \n",
       "13           0.161723      0.162474           0.191006      0.168407   \n",
       "14           0.161750      0.163322           0.190948      0.168404   \n",
       "15           0.160438      0.162332           0.189557      0.167908   \n",
       "\n",
       "    val_pr_auc_near_3  val_pr_auc_3  val_pr_auc_near_4  val_pr_auc_4  \\\n",
       "0            0.143216      0.123820           0.131218      0.125694   \n",
       "1            0.142813      0.123439           0.130563      0.125050   \n",
       "2            0.142176      0.123082           0.130075      0.124137   \n",
       "3            0.141925      0.123119           0.130242      0.125001   \n",
       "4            0.141187      0.123432           0.133065      0.126577   \n",
       "5            0.143173      0.124383           0.133261      0.127327   \n",
       "6            0.142757      0.124305           0.132593      0.126327   \n",
       "7            0.144538      0.124941           0.133889      0.127963   \n",
       "8            0.140842      0.122617           0.128429      0.123759   \n",
       "9            0.140779      0.121947           0.129759      0.125277   \n",
       "10           0.140610      0.122157           0.129993      0.124670   \n",
       "11           0.141883      0.122430           0.127209      0.123386   \n",
       "12           0.142138      0.123486           0.130762      0.124594   \n",
       "13           0.142149      0.122890           0.131219      0.125406   \n",
       "14           0.139990      0.122780           0.131664      0.125794   \n",
       "15           0.142023      0.123051           0.131156      0.126033   \n",
       "\n",
       "    val_pr_auc_near_5  val_pr_auc_5  \n",
       "0            0.140735      0.131620  \n",
       "1            0.142261      0.131808  \n",
       "2            0.142039      0.132118  \n",
       "3            0.140601      0.131839  \n",
       "4            0.140374      0.130755  \n",
       "5            0.141259      0.131103  \n",
       "6            0.141685      0.131386  \n",
       "7            0.143071      0.132283  \n",
       "8            0.141372      0.131742  \n",
       "9            0.140836      0.131464  \n",
       "10           0.142234      0.132046  \n",
       "11           0.142033      0.132084  \n",
       "12           0.142259      0.131669  \n",
       "13           0.142250      0.132223  \n",
       "14           0.141398      0.132029  \n",
       "15           0.142284      0.131420  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac95421",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2899d049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '3V6Z85P6VTN8HD0C',\n",
       "  'HostId': '6/ICDkfMkO+onLpTmPu5GH5qn01YuIg/Cc6In+lo3qhwm9y4rR7W8tsem8zUQhagN+PZ32tAkjM=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': '6/ICDkfMkO+onLpTmPu5GH5qn01YuIg/Cc6In+lo3qhwm9y4rR7W8tsem8zUQhagN+PZ32tAkjM=',\n",
       "   'x-amz-request-id': '3V6Z85P6VTN8HD0C',\n",
       "   'date': 'Wed, 14 May 2025 12:42:38 GMT',\n",
       "   'x-amz-server-side-encryption': 'AES256',\n",
       "   'etag': '\"bb6c8a392cb752e6a260e0384c09a9d2\"',\n",
       "   'x-amz-checksum-crc32': 'pCB1XQ==',\n",
       "   'x-amz-checksum-type': 'FULL_OBJECT',\n",
       "   'content-length': '0',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"bb6c8a392cb752e6a260e0384c09a9d2\"',\n",
       " 'ChecksumCRC32': 'pCB1XQ==',\n",
       " 'ChecksumType': 'FULL_OBJECT',\n",
       " 'ServerSideEncryption': 'AES256'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from io import StringIO\n",
    "s3 = boto3.client('s3')  # assumes you've run aws configure or have IAM role\n",
    "# Create a CSV in memory\n",
    "csv_buffer = StringIO()\n",
    "grid_sparse.to_csv(csv_buffer, index=False)\n",
    "s3.put_object(\n",
    "    Bucket='kehmisjan2025',\n",
    "    Key='gridseach_catboost_051425.csv',\n",
    "    Body=csv_buffer.getvalue()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2b274c",
   "metadata": {},
   "source": [
    "Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c74b0114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify available numeric and categorical columns\n",
    "numeric_cols = iit_data.select_dtypes(include='number').drop(columns=[\"iit\", \"SiteCode\"], errors='ignore').columns.tolist()\n",
    "categorical_cols = iit_data.select_dtypes(include='object').columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287c18a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "85882743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import xgboost as xgb\n",
    "\n",
    "def custom_mode_imputer(column, exclude=\"NR\"):\n",
    "    counter = Counter(column.dropna())\n",
    "    if exclude in counter:\n",
    "        del counter[exclude]\n",
    "    return counter.most_common(1)[0][0] if counter else None\n",
    "\n",
    "def impute_data(df, cat_impute_values=None, num_impute_values=None, fit=False, categorical_cols=None, numeric_cols=None):\n",
    "    if fit:\n",
    "        cat_impute_values = {}\n",
    "        num_impute_values = {}\n",
    "        for col in categorical_cols:\n",
    "            cat_impute_values[col] = custom_mode_imputer(df[col], exclude=\"NR\")\n",
    "        for col in numeric_cols:\n",
    "            num_impute_values[col] = df[col].mean()\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        df[col] = df[col].fillna(cat_impute_values.get(col, \"Unknown\"))\n",
    "    for col in numeric_cols:\n",
    "        df[col] = df[col].fillna(num_impute_values.get(col, 0))\n",
    "        \n",
    "    return df, cat_impute_values, num_impute_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "608eb378",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5914/1013458479.py:21: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(cat_impute_values.get(col, \"Unknown\"))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Invalid value '0.066305066410241' for dtype Int64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/internals/blocks.py:2328\u001b[0m, in \u001b[0;36mExtensionBlock.fillna\u001b[0;34m(self, value, limit, inplace, downcast, using_cow, already_warned)\u001b[0m\n\u001b[1;32m   2327\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2328\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[1;32m   2330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   2332\u001b[0m     \u001b[38;5;66;03m# 3rd party EA that has not implemented copy keyword yet\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/arrays/masked.py:266\u001b[0m, in \u001b[0;36mBaseMaskedArray.fillna\u001b[0;34m(self, value, method, limit, copy)\u001b[0m\n\u001b[1;32m    265\u001b[0m             new_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m[:]\n\u001b[0;32m--> 266\u001b[0m         \u001b[43mnew_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/arrays/masked.py:314\u001b[0m, in \u001b[0;36mBaseMaskedArray.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 314\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_setitem_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data[key] \u001b[38;5;241m=\u001b[39m value\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/arrays/masked.py:305\u001b[0m, in \u001b[0;36mBaseMaskedArray._validate_setitem_value\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;66;03m# TODO: unsigned checks\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \n\u001b[1;32m    303\u001b[0m \u001b[38;5;66;03m# Note: without the \"str\" here, the f-string rendering raises in\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;66;03m#  py38 builds.\u001b[39;00m\n\u001b[0;32m--> 305\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid value \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(value)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for dtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid value '0.066305066410241' for dtype Int64",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m train_data1 \u001b[38;5;241m=\u001b[39m train_data1[(train_data1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNAD\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2023-01-01\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m&\u001b[39m (train_data1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNAD\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2023-05-31\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Impute train data and get imputation values\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m train_data1, cat_impute_values, num_impute_values \u001b[38;5;241m=\u001b[39m \u001b[43mimpute_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcategorical_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnumeric_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_cols\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m train_data1 \u001b[38;5;241m=\u001b[39m encode_xgboost(train_data1)\n\u001b[1;32m     16\u001b[0m train_labels1 \u001b[38;5;241m=\u001b[39m train_data1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miit\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "Cell \u001b[0;32mIn[59], line 23\u001b[0m, in \u001b[0;36mimpute_data\u001b[0;34m(df, cat_impute_values, num_impute_values, fit, categorical_cols, numeric_cols)\u001b[0m\n\u001b[1;32m     21\u001b[0m     df[col] \u001b[38;5;241m=\u001b[39m df[col]\u001b[38;5;241m.\u001b[39mfillna(cat_impute_values\u001b[38;5;241m.\u001b[39mget(col, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m numeric_cols:\n\u001b[0;32m---> 23\u001b[0m     df[col] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_impute_values\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df, cat_impute_values, num_impute_values\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/generic.py:7349\u001b[0m, in \u001b[0;36mNDFrame.fillna\u001b[0;34m(self, value, method, axis, inplace, limit, downcast)\u001b[0m\n\u001b[1;32m   7342\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   7343\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   7344\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m parameter must be a scalar, dict \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   7345\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor Series, but you passed a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   7346\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   7347\u001b[0m         )\n\u001b[0;32m-> 7349\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   7350\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdowncast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdowncast\u001b[49m\n\u001b[1;32m   7351\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   7353\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, (\u001b[38;5;28mdict\u001b[39m, ABCSeries)):\n\u001b[1;32m   7354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/internals/base.py:186\u001b[0m, in \u001b[0;36mDataManager.fillna\u001b[0;34m(self, value, limit, inplace, downcast)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m limit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Do this validation even if we go through one of the no-op paths\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     limit \u001b[38;5;241m=\u001b[39m libalgos\u001b[38;5;241m.\u001b[39mvalidate_limit(\u001b[38;5;28;01mNone\u001b[39;00m, limit\u001b[38;5;241m=\u001b[39mlimit)\n\u001b[0;32m--> 186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_with_block\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfillna\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdowncast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdowncast\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43malready_warned\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_AlreadyWarned\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/internals/managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/internals/blocks.py:2334\u001b[0m, in \u001b[0;36mExtensionBlock.fillna\u001b[0;34m(self, value, limit, inplace, downcast, using_cow, already_warned)\u001b[0m\n\u001b[1;32m   2331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   2332\u001b[0m     \u001b[38;5;66;03m# 3rd party EA that has not implemented copy keyword yet\u001b[39;00m\n\u001b[1;32m   2333\u001b[0m     refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2334\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2335\u001b[0m     \u001b[38;5;66;03m# issue the warning *after* retrying, in case the TypeError\u001b[39;00m\n\u001b[1;32m   2336\u001b[0m     \u001b[38;5;66;03m#  was caused by an invalid fill_value\u001b[39;00m\n\u001b[1;32m   2337\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2338\u001b[0m         \u001b[38;5;66;03m# GH#53278\u001b[39;00m\n\u001b[1;32m   2339\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtensionArray.fillna added a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcopy\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keyword in pandas \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2345\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m   2346\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/arrays/masked.py:266\u001b[0m, in \u001b[0;36mBaseMaskedArray.fillna\u001b[0;34m(self, value, method, limit, copy)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    265\u001b[0m             new_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m[:]\n\u001b[0;32m--> 266\u001b[0m         \u001b[43mnew_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m copy:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/arrays/masked.py:314\u001b[0m, in \u001b[0;36mBaseMaskedArray.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mask[key] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 314\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_setitem_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data[key] \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mask[key] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/arrays/masked.py:305\u001b[0m, in \u001b[0;36mBaseMaskedArray._validate_setitem_value\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;66;03m# TODO: unsigned checks\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \n\u001b[1;32m    303\u001b[0m \u001b[38;5;66;03m# Note: without the \"str\" here, the f-string rendering raises in\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;66;03m#  py38 builds.\u001b[39;00m\n\u001b[0;32m--> 305\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid value \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(value)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for dtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid value '0.066305066410241' for dtype Int64"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# ========== Train Data (Jan–May 2023) ==========\n",
    "train_data1 = iit_data.copy().drop(columns=[\"SiteCode\"])\n",
    "train_data1 = train_data1[(train_data1[\"NAD\"] >= \"2023-01-01\") & (train_data1[\"NAD\"] <= \"2023-05-31\")]\n",
    "# Impute train data and get imputation values\n",
    "train_data1, cat_impute_values, num_impute_values = impute_data(\n",
    "    train_data1,\n",
    "    fit=True,\n",
    "    categorical_cols=categorical_cols,\n",
    "    numeric_cols=numeric_cols\n",
    ")\n",
    "\n",
    "train_data1 = encode_xgboost(train_data1)\n",
    "train_labels1 = train_data1[\"iit\"]\n",
    "train_features1 = train_data1.drop(columns=[\"key\", \"NAD\", \"iit\"])\n",
    "\n",
    "# ========== Validation Data (June 2023) ==========\n",
    "val_data1 = iit_data.copy().drop(columns=[\"SiteCode\"])\n",
    "val_data1 = val_data1[(val_data1[\"NAD\"] >= \"2023-06-01\") & (val_data1[\"NAD\"] <= \"2023-06-30\")]\n",
    "val_data1, _, _ = impute_data(\n",
    "    val_data1,\n",
    "    cat_impute_values=cat_impute_values,\n",
    "    num_impute_values=num_impute_values,\n",
    "    categorical_cols=categorical_cols,\n",
    "    numeric_cols=numeric_cols\n",
    ")\n",
    "\n",
    "val_data1 = encode_xgboost(val_data1)\n",
    "val_labels1 = val_data1[\"iit\"]\n",
    "val_features1 = val_data1.drop(columns=[\"key\", \"NAD\", \"iit\"])\n",
    "\n",
    "# ========== Test Near Data (July 2023) ==========\n",
    "testnear_data1 = iit_data.copy().drop(columns=[\"SiteCode\"])\n",
    "testnear_data1 = testnear_data1[(testnear_data1[\"NAD\"] >= \"2023-07-01\") & (testnear_data1[\"NAD\"] <= \"2023-07-31\")]\n",
    "\n",
    "testnear_data1, _, _ = impute_data(\n",
    "    testnear_data1,\n",
    "    cat_impute_values=cat_impute_values,\n",
    "    num_impute_values=num_impute_values,\n",
    "    categorical_cols=categorical_cols,\n",
    "    numeric_cols=numeric_cols\n",
    ")\n",
    "\n",
    "testnear_data1 = encode_xgboost(testnear_data1)\n",
    "testnear_labels1 = testnear_data1[\"iit\"]\n",
    "testnear_features1 = testnear_data1.drop(columns=[\"key\", \"NAD\", \"iit\"])\n",
    "\n",
    "# ========== Test Data (July–Sept 2023) ==========\n",
    "test_data1 = iit_data.copy().drop(columns=[\"SiteCode\"])\n",
    "test_data1 = test_data1[(test_data1[\"NAD\"] >= \"2023-07-01\") & (test_data1[\"NAD\"] <= \"2023-09-30\")]\n",
    "test_data1, _, _ = impute_data(\n",
    "    test_data1,\n",
    "    cat_impute_values=cat_impute_values,\n",
    "    num_impute_values=num_impute_values,\n",
    "    categorical_cols=categorical_cols,\n",
    "    numeric_cols=numeric_cols\n",
    ")\n",
    "\n",
    "test_data1 = encode_xgboost(test_data1)\n",
    "test_labels1 = test_data1[\"iit\"]\n",
    "test_features1 = test_data1.drop(columns=[\"key\", \"NAD\", \"iit\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a157686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fold 2\n",
    "# Train Data (Jan–May 2023)\n",
    "train_data2 = iit_data.copy()\n",
    "train_data2 = train_data2.drop(columns=[\"SiteCode\"])\n",
    "train_data2 = train_data2[(train_data2[\"NAD\"] >= \"2023-04-01\") & (train_data2[\"NAD\"] <= \"2023-08-30\")]\n",
    "train_data2 = encode_xgboost(train_data2)\n",
    "train_labels2 = train_data2[\"iit\"]\n",
    "train_features2 = train_data2.drop(columns=[\"key\", \"NAD\", \"iit\"])\n",
    "\n",
    "\n",
    "\n",
    "# Validation Data (June 2023)\n",
    "val_data2 = iit_data.copy()\n",
    "val_data2 = val_data2.drop(columns=[\"SiteCode\"])\n",
    "val_data2 = val_data2[(val_data2[\"NAD\"] >= \"2023-09-01\") & (val_data2[\"NAD\"] <= \"2023-09-30\")]\n",
    "val_data2 = encode_xgboost(val_data2)\n",
    "val_labels2 = val_data2[\"iit\"]\n",
    "val_features2 = val_data2.drop(columns=[\"key\", \"NAD\", \"iit\"])\n",
    "\n",
    "\n",
    "\n",
    "# Test Near Data (July 2023)\n",
    "testnear_data2 = iit_data.copy()\n",
    "testnear_data2 = testnear_data2.drop(columns=[\"SiteCode\"])\n",
    "testnear_data2 = testnear_data2[(testnear_data2[\"NAD\"] >= \"2023-10-01\") & (testnear_data2[\"NAD\"] <= \"2023-10-31\")]\n",
    "testnear_data2 = encode_xgboost(testnear_data2)\n",
    "testnear_labels2 = testnear_data2[\"iit\"]\n",
    "testnear_features2 = testnear_data2.drop(columns=[\"key\", \"NAD\", \"iit\"])\n",
    "\n",
    "\n",
    "# Test Data (July–Sept 2023)\n",
    "test_data2 = iit_data.copy()\n",
    "test_data2 = test_data2.drop(columns=[\"SiteCode\"])\n",
    "test_data2 = test_data2[(test_data2[\"NAD\"] >= \"2023-10-01\") & (test_data2[\"NAD\"] <= \"2023-12-31\")]\n",
    "test_data2 = encode_xgboost(test_data2)\n",
    "test_labels2 = test_data2[\"iit\"]\n",
    "test_features2 = test_data2.drop(columns=[\"key\", \"NAD\", \"iit\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "23f57ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/.local/lib/python3.9/site-packages/numpy/_core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nAdaBoostClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 10\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Define and train the model\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m AdaBoostClassifier(\n\u001b[1;32m      5\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mDecisionTreeClassifier(max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m),\n\u001b[1;32m      6\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m      7\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,\n\u001b[1;32m      8\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[1;32m      9\u001b[0m )\n\u001b[0;32m---> 10\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_features1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Validation\u001b[39;00m\n\u001b[1;32m     13\u001b[0m val_preds_proba \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(val_features1)[:, \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:130\u001b[0m, in \u001b[0;36mBaseWeightBoosting.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Build a boosted classifier/regressor from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;124;03m    Fitted estimator.\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m _raise_for_unsupported_routing(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n\u001b[0;32m--> 130\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_regressor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(\n\u001b[1;32m    142\u001b[0m     sample_weight, X, np\u001b[38;5;241m.\u001b[39mfloat64, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, ensure_non_negative\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    143\u001b[0m )\n\u001b[1;32m    144\u001b[0m sample_weight \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m sample_weight\u001b[38;5;241m.\u001b[39msum()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:2961\u001b[0m, in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2959\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m   2960\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2961\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2962\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m   2964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1370\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1366\u001b[0m     )\n\u001b[1;32m   1368\u001b[0m ensure_all_finite \u001b[38;5;241m=\u001b[39m _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[0;32m-> 1370\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1371\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1375\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1382\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1384\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1385\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1387\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1389\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1107\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1102\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1103\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m   1104\u001b[0m     )\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[0;32m-> 1107\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[1;32m   1115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[1;32m   1116\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:120\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:169\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    155\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    168\u001b[0m     )\n\u001b[0;32m--> 169\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nAdaBoostClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "# Define and train the model\n",
    "model = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=3),\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.5,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(train_features1, train_labels1)\n",
    "\n",
    "# Validation\n",
    "val_preds_proba = model.predict_proba(val_features1)[:, 1]\n",
    "val_auc = roc_auc_score(val_labels1, val_preds_proba)\n",
    "print(f\"Validation AUC: {val_auc:.4f}\")\n",
    "val_aucpr = average_precision_score(val_labels1, val_preds_proba)\n",
    "print(f\"Validation AUC-PR: {val_aucpr:.4f}\")\n",
    "\n",
    "# Test Near (July)\n",
    "testnear_preds_proba = model.predict_proba(testnear_features1)[:, 1]\n",
    "testnear_auc = roc_auc_score(testnear_labels1, testnear_preds_proba)\n",
    "print(f\"Test Near AUC (July): {testnear_auc:.4f}\")\n",
    "\n",
    "# Test (July–Sept)\n",
    "test_preds_proba = model.predict_proba(test_features1)[:, 1]\n",
    "test_auc = roc_auc_score(test_labels1, test_preds_proba)\n",
    "print(f\"Test AUC (July–Sept): {test_auc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
